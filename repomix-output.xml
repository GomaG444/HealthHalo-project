This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
HealthHalo-project/
  heart.csv
  LSTM Analysis.py
  ml_model.py
  monthly_dataset_for_LSTM.py
  real_time_LSTM_simulation.py
static/
  script.js
templates/
  chatbot.html
  index.html
  upload.html
.gitignore
app.py
README.md
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="templates/upload.html">
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>HealthHalo Chat with AI</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 text-gray-900 font-sans">
  <div class="max-w-lg mx-auto mt-10 p-6 bg-white rounded-3xl shadow-xl">

    <!-- Header -->
    <div class="text-center mb-6">
      <div class="flex justify-center items-center gap-2">
        <img src="{{ url_for('static', filename='images/logo.png') }}" class="h-8" alt="Logo">
        <h1 class="text-2xl font-bold text-blue-900">Upload Data</h1>
      </div>
      <p class="text-sm text-gray-600">Drop a csv of your health data here</p>
       <input type="text" id="chatInput" placeholder="Add your csv file" class="flex-1 border border-gray-300 rounded-md px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-blue-400">
       <button> Submit </button>
    </div>
</file>

<file path="HealthHalo-project/heart.csv">
age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal,target
63,1,3,145,233,1,0,150,0,2.3,0,0,1,1
37,1,2,130,250,0,1,187,0,3.5,0,0,2,1
41,0,1,130,204,0,0,172,0,1.4,2,0,2,1
56,1,1,120,236,0,1,178,0,0.8,2,0,2,1
57,0,0,120,354,0,1,163,1,0.6,2,0,2,1
57,1,0,140,192,0,1,148,0,0.4,1,0,1,1
56,0,1,140,294,0,0,153,0,1.3,1,0,2,1
44,1,1,120,263,0,1,173,0,0,2,0,3,1
52,1,2,172,199,1,1,162,0,0.5,2,0,3,1
57,1,2,150,168,0,1,174,0,1.6,2,0,2,1
54,1,0,140,239,0,1,160,0,1.2,2,0,2,1
48,0,2,130,275,0,1,139,0,0.2,2,0,2,1
49,1,1,130,266,0,1,171,0,0.6,2,0,2,1
64,1,3,110,211,0,0,144,1,1.8,1,0,2,1
58,0,3,150,283,1,0,162,0,1,2,0,2,1
50,0,2,120,219,0,1,158,0,1.6,1,0,2,1
58,0,2,120,340,0,1,172,0,0,2,0,2,1
66,0,3,150,226,0,1,114,0,2.6,0,0,2,1
43,1,0,150,247,0,1,171,0,1.5,2,0,2,1
69,0,3,140,239,0,1,151,0,1.8,2,2,2,1
59,1,0,135,234,0,1,161,0,0.5,1,0,3,1
44,1,2,130,233,0,1,179,1,0.4,2,0,2,1
42,1,0,140,226,0,1,178,0,0,2,0,2,1
61,1,2,150,243,1,1,137,1,1,1,0,2,1
40,1,3,140,199,0,1,178,1,1.4,2,0,3,1
71,0,1,160,302,0,1,162,0,0.4,2,2,2,1
59,1,2,150,212,1,1,157,0,1.6,2,0,2,1
51,1,2,110,175,0,1,123,0,0.6,2,0,2,1
65,0,2,140,417,1,0,157,0,0.8,2,1,2,1
53,1,2,130,197,1,0,152,0,1.2,0,0,2,1
41,0,1,105,198,0,1,168,0,0,2,1,2,1
65,1,0,120,177,0,1,140,0,0.4,2,0,3,1
44,1,1,130,219,0,0,188,0,0,2,0,2,1
54,1,2,125,273,0,0,152,0,0.5,0,1,2,1
51,1,3,125,213,0,0,125,1,1.4,2,1,2,1
46,0,2,142,177,0,0,160,1,1.4,0,0,2,1
54,0,2,135,304,1,1,170,0,0,2,0,2,1
54,1,2,150,232,0,0,165,0,1.6,2,0,3,1
65,0,2,155,269,0,1,148,0,0.8,2,0,2,1
65,0,2,160,360,0,0,151,0,0.8,2,0,2,1
51,0,2,140,308,0,0,142,0,1.5,2,1,2,1
48,1,1,130,245,0,0,180,0,0.2,1,0,2,1
45,1,0,104,208,0,0,148,1,3,1,0,2,1
53,0,0,130,264,0,0,143,0,0.4,1,0,2,1
39,1,2,140,321,0,0,182,0,0,2,0,2,1
52,1,1,120,325,0,1,172,0,0.2,2,0,2,1
44,1,2,140,235,0,0,180,0,0,2,0,2,1
47,1,2,138,257,0,0,156,0,0,2,0,2,1
53,0,2,128,216,0,0,115,0,0,2,0,0,1
53,0,0,138,234,0,0,160,0,0,2,0,2,1
51,0,2,130,256,0,0,149,0,0.5,2,0,2,1
66,1,0,120,302,0,0,151,0,0.4,1,0,2,1
62,1,2,130,231,0,1,146,0,1.8,1,3,3,1
44,0,2,108,141,0,1,175,0,0.6,1,0,2,1
63,0,2,135,252,0,0,172,0,0,2,0,2,1
52,1,1,134,201,0,1,158,0,0.8,2,1,2,1
48,1,0,122,222,0,0,186,0,0,2,0,2,1
45,1,0,115,260,0,0,185,0,0,2,0,2,1
34,1,3,118,182,0,0,174,0,0,2,0,2,1
57,0,0,128,303,0,0,159,0,0,2,1,2,1
71,0,2,110,265,1,0,130,0,0,2,1,2,1
54,1,1,108,309,0,1,156,0,0,2,0,3,1
52,1,3,118,186,0,0,190,0,0,1,0,1,1
41,1,1,135,203,0,1,132,0,0,1,0,1,1
58,1,2,140,211,1,0,165,0,0,2,0,2,1
35,0,0,138,183,0,1,182,0,1.4,2,0,2,1
51,1,2,100,222,0,1,143,1,1.2,1,0,2,1
45,0,1,130,234,0,0,175,0,0.6,1,0,2,1
44,1,1,120,220,0,1,170,0,0,2,0,2,1
62,0,0,124,209,0,1,163,0,0,2,0,2,1
54,1,2,120,258,0,0,147,0,0.4,1,0,3,1
51,1,2,94,227,0,1,154,1,0,2,1,3,1
29,1,1,130,204,0,0,202,0,0,2,0,2,1
51,1,0,140,261,0,0,186,1,0,2,0,2,1
43,0,2,122,213,0,1,165,0,0.2,1,0,2,1
55,0,1,135,250,0,0,161,0,1.4,1,0,2,1
51,1,2,125,245,1,0,166,0,2.4,1,0,2,1
59,1,1,140,221,0,1,164,1,0,2,0,2,1
52,1,1,128,205,1,1,184,0,0,2,0,2,1
58,1,2,105,240,0,0,154,1,0.6,1,0,3,1
41,1,2,112,250,0,1,179,0,0,2,0,2,1
45,1,1,128,308,0,0,170,0,0,2,0,2,1
60,0,2,102,318,0,1,160,0,0,2,1,2,1
52,1,3,152,298,1,1,178,0,1.2,1,0,3,1
42,0,0,102,265,0,0,122,0,0.6,1,0,2,1
67,0,2,115,564,0,0,160,0,1.6,1,0,3,1
68,1,2,118,277,0,1,151,0,1,2,1,3,1
46,1,1,101,197,1,1,156,0,0,2,0,3,1
54,0,2,110,214,0,1,158,0,1.6,1,0,2,1
58,0,0,100,248,0,0,122,0,1,1,0,2,1
48,1,2,124,255,1,1,175,0,0,2,2,2,1
57,1,0,132,207,0,1,168,1,0,2,0,3,1
52,1,2,138,223,0,1,169,0,0,2,4,2,1
54,0,1,132,288,1,0,159,1,0,2,1,2,1
45,0,1,112,160,0,1,138,0,0,1,0,2,1
53,1,0,142,226,0,0,111,1,0,2,0,3,1
62,0,0,140,394,0,0,157,0,1.2,1,0,2,1
52,1,0,108,233,1,1,147,0,0.1,2,3,3,1
43,1,2,130,315,0,1,162,0,1.9,2,1,2,1
53,1,2,130,246,1,0,173,0,0,2,3,2,1
42,1,3,148,244,0,0,178,0,0.8,2,2,2,1
59,1,3,178,270,0,0,145,0,4.2,0,0,3,1
63,0,1,140,195,0,1,179,0,0,2,2,2,1
42,1,2,120,240,1,1,194,0,0.8,0,0,3,1
50,1,2,129,196,0,1,163,0,0,2,0,2,1
68,0,2,120,211,0,0,115,0,1.5,1,0,2,1
69,1,3,160,234,1,0,131,0,0.1,1,1,2,1
45,0,0,138,236,0,0,152,1,0.2,1,0,2,1
50,0,1,120,244,0,1,162,0,1.1,2,0,2,1
50,0,0,110,254,0,0,159,0,0,2,0,2,1
64,0,0,180,325,0,1,154,1,0,2,0,2,1
57,1,2,150,126,1,1,173,0,0.2,2,1,3,1
64,0,2,140,313,0,1,133,0,0.2,2,0,3,1
43,1,0,110,211,0,1,161,0,0,2,0,3,1
55,1,1,130,262,0,1,155,0,0,2,0,2,1
37,0,2,120,215,0,1,170,0,0,2,0,2,1
41,1,2,130,214,0,0,168,0,2,1,0,2,1
56,1,3,120,193,0,0,162,0,1.9,1,0,3,1
46,0,1,105,204,0,1,172,0,0,2,0,2,1
46,0,0,138,243,0,0,152,1,0,1,0,2,1
64,0,0,130,303,0,1,122,0,2,1,2,2,1
59,1,0,138,271,0,0,182,0,0,2,0,2,1
41,0,2,112,268,0,0,172,1,0,2,0,2,1
54,0,2,108,267,0,0,167,0,0,2,0,2,1
39,0,2,94,199,0,1,179,0,0,2,0,2,1
34,0,1,118,210,0,1,192,0,0.7,2,0,2,1
47,1,0,112,204,0,1,143,0,0.1,2,0,2,1
67,0,2,152,277,0,1,172,0,0,2,1,2,1
52,0,2,136,196,0,0,169,0,0.1,1,0,2,1
74,0,1,120,269,0,0,121,1,0.2,2,1,2,1
54,0,2,160,201,0,1,163,0,0,2,1,2,1
49,0,1,134,271,0,1,162,0,0,1,0,2,1
42,1,1,120,295,0,1,162,0,0,2,0,2,1
41,1,1,110,235,0,1,153,0,0,2,0,2,1
41,0,1,126,306,0,1,163,0,0,2,0,2,1
49,0,0,130,269,0,1,163,0,0,2,0,2,1
60,0,2,120,178,1,1,96,0,0,2,0,2,1
62,1,1,128,208,1,0,140,0,0,2,0,2,1
57,1,0,110,201,0,1,126,1,1.5,1,0,1,1
64,1,0,128,263,0,1,105,1,0.2,1,1,3,1
51,0,2,120,295,0,0,157,0,0.6,2,0,2,1
43,1,0,115,303,0,1,181,0,1.2,1,0,2,1
42,0,2,120,209,0,1,173,0,0,1,0,2,1
67,0,0,106,223,0,1,142,0,0.3,2,2,2,1
76,0,2,140,197,0,2,116,0,1.1,1,0,2,1
70,1,1,156,245,0,0,143,0,0,2,0,2,1
44,0,2,118,242,0,1,149,0,0.3,1,1,2,1
60,0,3,150,240,0,1,171,0,0.9,2,0,2,1
44,1,2,120,226,0,1,169,0,0,2,0,2,1
42,1,2,130,180,0,1,150,0,0,2,0,2,1
66,1,0,160,228,0,0,138,0,2.3,2,0,1,1
71,0,0,112,149,0,1,125,0,1.6,1,0,2,1
64,1,3,170,227,0,0,155,0,0.6,1,0,3,1
66,0,2,146,278,0,0,152,0,0,1,1,2,1
39,0,2,138,220,0,1,152,0,0,1,0,2,1
58,0,0,130,197,0,1,131,0,0.6,1,0,2,1
47,1,2,130,253,0,1,179,0,0,2,0,2,1
35,1,1,122,192,0,1,174,0,0,2,0,2,1
58,1,1,125,220,0,1,144,0,0.4,1,4,3,1
56,1,1,130,221,0,0,163,0,0,2,0,3,1
56,1,1,120,240,0,1,169,0,0,0,0,2,1
55,0,1,132,342,0,1,166,0,1.2,2,0,2,1
41,1,1,120,157,0,1,182,0,0,2,0,2,1
38,1,2,138,175,0,1,173,0,0,2,4,2,1
38,1,2,138,175,0,1,173,0,0,2,4,2,1
67,1,0,160,286,0,0,108,1,1.5,1,3,2,0
67,1,0,120,229,0,0,129,1,2.6,1,2,3,0
62,0,0,140,268,0,0,160,0,3.6,0,2,2,0
63,1,0,130,254,0,0,147,0,1.4,1,1,3,0
53,1,0,140,203,1,0,155,1,3.1,0,0,3,0
56,1,2,130,256,1,0,142,1,0.6,1,1,1,0
48,1,1,110,229,0,1,168,0,1,0,0,3,0
58,1,1,120,284,0,0,160,0,1.8,1,0,2,0
58,1,2,132,224,0,0,173,0,3.2,2,2,3,0
60,1,0,130,206,0,0,132,1,2.4,1,2,3,0
40,1,0,110,167,0,0,114,1,2,1,0,3,0
60,1,0,117,230,1,1,160,1,1.4,2,2,3,0
64,1,2,140,335,0,1,158,0,0,2,0,2,0
43,1,0,120,177,0,0,120,1,2.5,1,0,3,0
57,1,0,150,276,0,0,112,1,0.6,1,1,1,0
55,1,0,132,353,0,1,132,1,1.2,1,1,3,0
65,0,0,150,225,0,0,114,0,1,1,3,3,0
61,0,0,130,330,0,0,169,0,0,2,0,2,0
58,1,2,112,230,0,0,165,0,2.5,1,1,3,0
50,1,0,150,243,0,0,128,0,2.6,1,0,3,0
44,1,0,112,290,0,0,153,0,0,2,1,2,0
60,1,0,130,253,0,1,144,1,1.4,2,1,3,0
54,1,0,124,266,0,0,109,1,2.2,1,1,3,0
50,1,2,140,233,0,1,163,0,0.6,1,1,3,0
41,1,0,110,172,0,0,158,0,0,2,0,3,0
51,0,0,130,305,0,1,142,1,1.2,1,0,3,0
58,1,0,128,216,0,0,131,1,2.2,1,3,3,0
54,1,0,120,188,0,1,113,0,1.4,1,1,3,0
60,1,0,145,282,0,0,142,1,2.8,1,2,3,0
60,1,2,140,185,0,0,155,0,3,1,0,2,0
59,1,0,170,326,0,0,140,1,3.4,0,0,3,0
46,1,2,150,231,0,1,147,0,3.6,1,0,2,0
67,1,0,125,254,1,1,163,0,0.2,1,2,3,0
62,1,0,120,267,0,1,99,1,1.8,1,2,3,0
65,1,0,110,248,0,0,158,0,0.6,2,2,1,0
44,1,0,110,197,0,0,177,0,0,2,1,2,0
60,1,0,125,258,0,0,141,1,2.8,1,1,3,0
58,1,0,150,270,0,0,111,1,0.8,2,0,3,0
68,1,2,180,274,1,0,150,1,1.6,1,0,3,0
62,0,0,160,164,0,0,145,0,6.2,0,3,3,0
52,1,0,128,255,0,1,161,1,0,2,1,3,0
59,1,0,110,239,0,0,142,1,1.2,1,1,3,0
60,0,0,150,258,0,0,157,0,2.6,1,2,3,0
49,1,2,120,188,0,1,139,0,2,1,3,3,0
59,1,0,140,177,0,1,162,1,0,2,1,3,0
57,1,2,128,229,0,0,150,0,0.4,1,1,3,0
61,1,0,120,260,0,1,140,1,3.6,1,1,3,0
39,1,0,118,219,0,1,140,0,1.2,1,0,3,0
61,0,0,145,307,0,0,146,1,1,1,0,3,0
56,1,0,125,249,1,0,144,1,1.2,1,1,2,0
43,0,0,132,341,1,0,136,1,3,1,0,3,0
62,0,2,130,263,0,1,97,0,1.2,1,1,3,0
63,1,0,130,330,1,0,132,1,1.8,2,3,3,0
65,1,0,135,254,0,0,127,0,2.8,1,1,3,0
48,1,0,130,256,1,0,150,1,0,2,2,3,0
63,0,0,150,407,0,0,154,0,4,1,3,3,0
55,1,0,140,217,0,1,111,1,5.6,0,0,3,0
65,1,3,138,282,1,0,174,0,1.4,1,1,2,0
56,0,0,200,288,1,0,133,1,4,0,2,3,0
54,1,0,110,239,0,1,126,1,2.8,1,1,3,0
70,1,0,145,174,0,1,125,1,2.6,0,0,3,0
62,1,1,120,281,0,0,103,0,1.4,1,1,3,0
35,1,0,120,198,0,1,130,1,1.6,1,0,3,0
59,1,3,170,288,0,0,159,0,0.2,1,0,3,0
64,1,2,125,309,0,1,131,1,1.8,1,0,3,0
47,1,2,108,243,0,1,152,0,0,2,0,2,0
57,1,0,165,289,1,0,124,0,1,1,3,3,0
55,1,0,160,289,0,0,145,1,0.8,1,1,3,0
64,1,0,120,246,0,0,96,1,2.2,0,1,2,0
70,1,0,130,322,0,0,109,0,2.4,1,3,2,0
51,1,0,140,299,0,1,173,1,1.6,2,0,3,0
58,1,0,125,300,0,0,171,0,0,2,2,3,0
60,1,0,140,293,0,0,170,0,1.2,1,2,3,0
77,1,0,125,304,0,0,162,1,0,2,3,2,0
35,1,0,126,282,0,0,156,1,0,2,0,3,0
70,1,2,160,269,0,1,112,1,2.9,1,1,3,0
59,0,0,174,249,0,1,143,1,0,1,0,2,0
64,1,0,145,212,0,0,132,0,2,1,2,1,0
57,1,0,152,274,0,1,88,1,1.2,1,1,3,0
56,1,0,132,184,0,0,105,1,2.1,1,1,1,0
48,1,0,124,274,0,0,166,0,0.5,1,0,3,0
56,0,0,134,409,0,0,150,1,1.9,1,2,3,0
66,1,1,160,246,0,1,120,1,0,1,3,1,0
54,1,1,192,283,0,0,195,0,0,2,1,3,0
69,1,2,140,254,0,0,146,0,2,1,3,3,0
51,1,0,140,298,0,1,122,1,4.2,1,3,3,0
43,1,0,132,247,1,0,143,1,0.1,1,4,3,0
62,0,0,138,294,1,1,106,0,1.9,1,3,2,0
67,1,0,100,299,0,0,125,1,0.9,1,2,2,0
59,1,3,160,273,0,0,125,0,0,2,0,2,0
45,1,0,142,309,0,0,147,1,0,1,3,3,0
58,1,0,128,259,0,0,130,1,3,1,2,3,0
50,1,0,144,200,0,0,126,1,0.9,1,0,3,0
62,0,0,150,244,0,1,154,1,1.4,1,0,2,0
38,1,3,120,231,0,1,182,1,3.8,1,0,3,0
66,0,0,178,228,1,1,165,1,1,1,2,3,0
52,1,0,112,230,0,1,160,0,0,2,1,2,0
53,1,0,123,282,0,1,95,1,2,1,2,3,0
63,0,0,108,269,0,1,169,1,1.8,1,2,2,0
54,1,0,110,206,0,0,108,1,0,1,1,2,0
66,1,0,112,212,0,0,132,1,0.1,2,1,2,0
55,0,0,180,327,0,2,117,1,3.4,1,0,2,0
49,1,2,118,149,0,0,126,0,0.8,2,3,2,0
54,1,0,122,286,0,0,116,1,3.2,1,2,2,0
56,1,0,130,283,1,0,103,1,1.6,0,0,3,0
46,1,0,120,249,0,0,144,0,0.8,2,0,3,0
61,1,3,134,234,0,1,145,0,2.6,1,2,2,0
67,1,0,120,237,0,1,71,0,1,1,0,2,0
58,1,0,100,234,0,1,156,0,0.1,2,1,3,0
47,1,0,110,275,0,0,118,1,1,1,1,2,0
52,1,0,125,212,0,1,168,0,1,2,2,3,0
58,1,0,146,218,0,1,105,0,2,1,1,3,0
57,1,1,124,261,0,1,141,0,0.3,2,0,3,0
58,0,1,136,319,1,0,152,0,0,2,2,2,0
61,1,0,138,166,0,0,125,1,3.6,1,1,2,0
42,1,0,136,315,0,1,125,1,1.8,1,0,1,0
52,1,0,128,204,1,1,156,1,1,1,0,0,0
59,1,2,126,218,1,1,134,0,2.2,1,1,1,0
40,1,0,152,223,0,1,181,0,0,2,0,3,0
61,1,0,140,207,0,0,138,1,1.9,2,1,3,0
46,1,0,140,311,0,1,120,1,1.8,1,2,3,0
59,1,3,134,204,0,1,162,0,0.8,2,2,2,0
57,1,1,154,232,0,0,164,0,0,2,1,2,0
57,1,0,110,335,0,1,143,1,3,1,1,3,0
55,0,0,128,205,0,2,130,1,2,1,1,3,0
61,1,0,148,203,0,1,161,0,0,2,1,3,0
58,1,0,114,318,0,2,140,0,4.4,0,3,1,0
58,0,0,170,225,1,0,146,1,2.8,1,2,1,0
67,1,2,152,212,0,0,150,0,0.8,1,0,3,0
44,1,0,120,169,0,1,144,1,2.8,0,0,1,0
63,1,0,140,187,0,0,144,1,4,2,2,3,0
63,0,0,124,197,0,1,136,1,0,1,0,2,0
59,1,0,164,176,1,0,90,0,1,1,2,1,0
57,0,0,140,241,0,1,123,1,0.2,1,0,3,0
45,1,3,110,264,0,1,132,0,1.2,1,0,3,0
68,1,0,144,193,1,1,141,0,3.4,1,2,3,0
57,1,0,130,131,0,1,115,1,1.2,1,1,3,0
57,0,1,130,236,0,0,174,0,0,1,1,2,0
</file>

<file path="HealthHalo-project/LSTM Analysis.py">
import streamlit as st
import random
from datetime import datetime, timedelta

# Page config
st.set_page_config(page_title="HealthHalo - LSTM Weekly Insights", layout="centered")

# Title
st.title("HealthHalo LSTM Analysis")
st.subheader("Weekly Heart Health Insights")

# Possible weekly messages
weekly_alerts = [
    "Stable readings this week — no major anomalies.",
    "Irregular heart rate patterns detected 3× in the past week.",
    "Slight increase in blood pressure and cholesterol levels.",
    "Heart rhythm and vitals appear normal and consistent.",
    "Elevated heart disease risk detected over multiple days!",
    "Noticed reduced activity this week — keep moving!",
    "Excellent consistency in heart health data this week.",
]

# Generate weekly summaries for the last 4 weeks
def generate_weekly_alerts():
    today = datetime.today()
    summaries = []
    for i in range(4):
        week_end = today - timedelta(days=i * 7)
        week_start = week_end - timedelta(days=6)
        summaries.append({
            "week_range": f"{week_start.strftime('%b %d')} - {week_end.strftime('%b %d')}",
            "alert": random.choice(weekly_alerts)
        })
    return summaries[::-1]  # Show oldest to newest

# Display weekly summaries
weekly_summaries = generate_weekly_alerts()
st.markdown("### Past 4 Weeks Overview")

for summary in weekly_summaries:
    st.markdown(f"** {summary['week_range']}**")
    st.info(summary['alert'])

# Footer
st.markdown("---")
st.caption(" HealthHalo · AI-Powered Insights · Prototype v1.0")
</file>

<file path="HealthHalo-project/ml_model.py">
import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import numpy as np

# Get the folder where this script is located
script_dir = os.path.dirname(os.path.abspath(__file__))

# Build the full path to the CSV file
csv_path = os.path.join(script_dir, 'heart.csv')

# Load the dataset
data = pd.read_csv(csv_path)

# Explore the dataset
print("Data Info:")
print(data.info())

print("\nMissing values per column:")
print(data.isnull().sum())

print("\nSummary statistics:")
print(data.describe())

# Quick look at data
print(data.head())

# Prepare features and target
X = data.drop('target', axis=1)  # assuming 'target' is the label column
y = data['target']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Logistic Regression model
model = LogisticRegression(max_iter=1000, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Evaluate the model
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Get feature importances (coefficients) from the trained Logistic Regression model
importances = np.abs(model.coef_[0])
features = X.columns

# Sort feature importances
indices = importances.argsort()[::-1]

# Plot
plt.figure(figsize=(10, 6))
plt.title("Feature Importance (Logistic Regression Coefficients)")
plt.bar(range(X.shape[1]), importances[indices], color="skyblue", align="center")
plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=45)
plt.tight_layout()
plt.show()
</file>

<file path="HealthHalo-project/monthly_dataset_for_LSTM.py">
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Set random seed for consistency
np.random.seed(42)

# Parameters
num_people = 5
readings_per_day = 48 # every 30 minutes
days = 30
total_readings = readings_per_day * days

# Generate timestamps
start_time = datetime(2025, 6, 1, 0, 0)
timestamps = [start_time + timedelta(minutes=30 * i) for i in range(total_readings)]

# Function to simulate a person’s data
def generate_person_data(person_id):
data = {
'person_id': [person_id] * total_readings,
'timestamp': [ts.strftime('%Y-%m-%d %H:%M:%S') for ts in timestamps],
'age': np.random.randint(40, 70),
'sex': np.random.randint(0, 2),
'cp': np.random.randint(0, 4, total_readings),
'trestbps': np.random.randint(90, 180, total_readings),
'chol': np.random.randint(150, 350, total_readings),
'fbs': np.random.randint(0, 2, total_readings),
'restecg': np.random.randint(0, 2, total_readings),
'thalach': np.random.randint(100, 202, total_readings),
'exang': np.random.randint(0, 2, total_readings),
'oldpeak': np.round(np.random.uniform(0, 6.2, total_readings), 1),
'slope': np.random.randint(0, 3, total_readings),
'ca': np.random.randint(0, 4, total_readings),
'thal': np.random.choice([0, 1, 2, 3], total_readings),
}

# Calculate a fake risk score
risk_score = (
(np.array(data['age']) > 50).astype(int)
+ (np.array(data['chol']) > 240).astype(int)
+ (np.array(data['thalach']) < 140).astype(int)
+ (np.array(data['trestbps']) > 130).astype(int)
+ (np.array(data['oldpeak']) > 2.5).astype(int)
)
data['heart_disease'] = (risk_score >= 3).astype(int)
return pd.DataFrame(data)

# Combine data for 5 people
df = pd.concat([generate_person_data(i + 1) for i in range(num_people)], ignore_index=True)
</file>

<file path="HealthHalo-project/real_time_LSTM_simulation.py">
import numpy as np
import pandas as pd
import time
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler

# Load model and prepare scaler
model = load_model("your_model.h5") # Save your trained model as this
scaler = MinMaxScaler()

# Load your existing dataset to fit the scaler
df = pd.read_csv("healthhalo_monthly_data_multiple_users.csv")
features = df.drop(columns=['person_id', 'timestamp', 'heart_disease'])
scaler.fit(features)

# Function to simulate incoming data (every 5 seconds)
def simulate_data_stream(seq_length=10):
buffer = []
for _ in range(100): # simulate 100 time steps
# Generate random new reading based on realistic bounds
new_data = {
'age': np.random.randint(40, 70),
'sex': np.random.randint(0, 2),
'cp': np.random.randint(0, 4),
'trestbps': np.random.randint(90, 180),
'chol': np.random.randint(150, 350),
'fbs': np.random.randint(0, 2),
'restecg': np.random.randint(0, 2),
'thalach': np.random.randint(100, 202),
'exang': np.random.randint(0, 2),
'oldpeak': np.round(np.random.uniform(0, 6.2), 1),
'slope': np.random.randint(0, 3),
'ca': np.random.randint(0, 4),
'thal': np.random.choice([0, 1, 2, 3])
}

df_new = pd.DataFrame([new_data])
df_scaled = scaler.transform(df_new)
buffer.append(df_scaled[0])

# Once buffer has enough data
if len(buffer) >= seq_length:
input_seq = np.array(buffer[-seq_length:]).reshape(1, seq_length, -1)
prediction = model.predict(input_seq)[0][0]

if prediction > 0.5:
print(f"🚨 ALERT: High risk of heart disease detected! (Risk: {prediction:.2f})")
else:
print(f"✅ Normal status. (Risk: {prediction:.2f})")

# Simulate delay between readings
time.sleep(5)

# Run simulation
simulate_data_stream()
</file>

<file path="static/script.js">
// Teachable Machine model URL
const URL = "https://teachablemachine.withgoogle.com/models/-q6hHNGve/";
let model, webcam, labelContainer, maxPredictions;
let currentAnimal = "";

// Initialize webcam and model
async function init() {
    const modelURL = URL + "model.json";
    const metadataURL = URL + "metadata.json";

    model = await tmImage.load(modelURL, metadataURL);
    maxPredictions = model.getTotalClasses();

    // Setup webcam
    const flip = true;
    webcam = new tmImage.Webcam(200, 200, flip);
    await webcam.setup();
    await webcam.play();
    window.requestAnimationFrame(loop);

    document.getElementById("webcam-container").appendChild(webcam.canvas);

    // Setup label container
    labelContainer = document.getElementById("label-container");
    for (let i = 0; i < maxPredictions; i++) {
        labelContainer.appendChild(document.createElement("div"));
    }
}

// Main prediction loop
async function loop() {
    webcam.update();
    await predict();
    window.requestAnimationFrame(loop);
}

// Predict function
async function predict() {
    const prediction = await model.predict(webcam.canvas);
    for (let i = 0; i < maxPredictions; i++) {
        const classPrediction = prediction[i].className + ": " + prediction[i].probability.toFixed(2);
        labelContainer.childNodes[i].innerHTML = classPrediction;
        if (prediction[i].probability > 0.5) {
            currentAnimal = prediction[i].className;
        }
    }
}

// Send message function
function sendMessage() {
    const userInput = document.getElementById("user-input").value;
    if (userInput.trim() === "") return;

    addMessageToChat(userInput, 'user');

    fetch('/chat', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            message: userInput,
            animalType: currentAnimal
        }),
    })
    .then(response => response.json())
    .then(data => {
        addMessageToChat(data.response, 'bot');
    })
    .catch((error) => {
        console.error('Error:', error);
    });

    document.getElementById("user-input").value = "";
}

// Add message to chat
function addMessageToChat(message, sender) {
    const chatContainer = document.getElementById("chat-container");
    const messageElement = document.createElement("div");
    messageElement.classList.add("message", sender + "-message");
    messageElement.textContent = message;
    chatContainer.appendChild(messageElement);
    chatContainer.scrollTop = chatContainer.scrollHeight;
}

// Event listener for Enter key
document.getElementById("user-input").addEventListener("keypress", function(event) {
    if (event.key === "Enter") {
        sendMessage();
    }
});
</file>

<file path="requirements.txt">
contourpy==1.3.0
cycler==0.12.1
fonttools==4.58.4
importlib_resources==6.5.2
joblib==1.5.1
kiwisolver==1.4.7
matplotlib==3.9.4
numpy==2.0.2
packaging==25.0
pandas==2.3.0
pillow==11.2.1
pyparsing==3.2.3
python-dateutil==2.9.0.post0
pytz==2025.2
scikit-learn==1.6.1
scipy==1.13.1
six==1.17.0
threadpoolctl==3.6.0
tzdata==2025.2
zipp==3.23.0
</file>

<file path=".gitignore">
# Ignore flask session folders
flask_session/
HealthHalo-project/flask_session/

# Ignore secrets file
secrets.txt

# Python related ignores (optional)
__pycache__/
*.pyc
*.pyo

#ignore api key
key.env
</file>

<file path="templates/chatbot.html">
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>HealthHalo Chat with AI</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 text-gray-900 font-sans">
  <div class="max-w-lg mx-auto mt-10 p-6 bg-white rounded-3xl shadow-xl">

    <!-- Header -->
    <div class="text-center mb-6">
      <div class="flex justify-center items-center gap-2">
        <img src="{{ url_for('static', filename='images/logo.png') }}" class="h-8" alt="Logo">
        <h1 class="text-2xl font-bold text-blue-900">HealthHalo Chat</h1>
      </div>
      <p class="text-sm text-gray-600">Your AI-powered health assistant</p>
    </div>

    <!-- Chatbox -->
    <div class="bg-gray-100 rounded-xl p-4 h-80 overflow-y-auto mb-4" id="chatMessages"></div>

    <!-- Input -->
    <div class="flex gap-2">
      <input type="text" id="chatInput" placeholder="Type your message..." class="flex-1 border border-gray-300 rounded-md px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-blue-400">
      <button onclick="sendMessage()" class="bg-blue-600 text-white rounded-md px-4 py-2 text-sm hover:bg-blue-700">Send</button>
    </div>

    <!-- Back Button -->
    <a href="{{ url_for('dashboard') }}" class="block mt-4 text-center text-blue-600 text-sm hover:underline">← Back to Dashboard</a>
  </div>

 <!-- Chat Script (Dynamic with OpenAI) -->
<script>
  let conversationStep = 0;
  let userData = {};

  // Use the API key passed from the Flask app
  const OPENAI_API_KEY = "{{ openai_api_key }}";

  async function sendMessage() {
    const input = document.getElementById('chatInput');
    const messages = document.getElementById('chatMessages');
    const userMessage = input.value.trim();
    if (!userMessage) return;

    messages.innerHTML += `<p><strong>You:</strong> ${userMessage}</p>`;
    messages.scrollTop = messages.scrollHeight;
    input.value = '';

    // Initial prompt to start conversation
    if (conversationStep === 0) {
      const prompt = "You are a friendly medical assistant AI. Start a conversation by asking about the user's health.";
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect symptoms
    else if (conversationStep === 1) {
      userData.symptoms = userMessage;
      const prompt = `You are a medical assistant AI. The user reported these symptoms: "${userData.symptoms}". Ask about their medication usage today.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect medications
    else if (conversationStep === 2) {
      userData.medications = userMessage;
      const prompt = `You are a medical assistant AI. The user reported these symptoms: "${userData.symptoms}" and medications: "${userData.medications}". Ask about their recent sleep, diet, or activity.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect lifestyle
    else if (conversationStep === 3) {
      userData.lifestyle = userMessage;
      const prompt = `You are a medical assistant AI. The user reported symptoms: "${userData.symptoms}", medications: "${userData.medications}", and lifestyle: "${userData.lifestyle}". Ask for their vitals in this format: age=55, sex=1, cholesterol=200, blood_pressure=120.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect vitals and get ML prediction
    else if (conversationStep === 4) {
      const features = {};
      userMessage.split(',').forEach(pair => {
        const [key, value] = pair.split('=').map(item => item.trim());
        if (key && value && !isNaN(value)) {
          features[key] = Number(value);
        }
      });

      if (Object.keys(features).length < 4) {
        messages.innerHTML += `<p><strong>AI:</strong> Please provide all four vitals correctly (age, sex, cholesterol, blood_pressure).</p>`;
        return;
      }

      try {
        const response = await fetch('/predict', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ features })
        });

        const data = await response.json();
        const riskScore = data.risk_score.toFixed(2);
        const predClass = data.predicted_class;

        const summary = `
Symptoms: ${userData.symptoms}
Medications: ${userData.medications}
Lifestyle: ${userData.lifestyle}
Vitals: ${JSON.stringify(features)}
Risk Score: ${riskScore}
Predicted Class: ${predClass}
        `;

        messages.innerHTML += `<p><strong>AI:</strong> Processing your data for a detailed summary...</p>`;
        await getLLMSummary(summary, messages);
      } catch (error) {
        messages.innerHTML += `<p><strong>AI:</strong> Failed to get risk score.</p>`;
      }

      const followUpPrompt = `You are a medical assistant AI. You have this patient data: "${summary}". Ask if they have other questions or want to schedule a check-in.`;
      const aiResponse = await getOpenAIResponse(followUpPrompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Handle follow-up or end conversation
    else {
      const prompt = `You are a medical assistant AI. The user has completed their check-in. End the conversation politely and offer to talk again soon.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
    }

    messages.scrollTop = messages.scrollHeight;
  }

  async function getOpenAIResponse(prompt) {
    try {
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages: [
            { role: "system", content: "You are a friendly medical assistant AI providing helpful and concise responses." },
            { role: "user", content: prompt }
          ],
          temperature: 0.7,
          max_tokens: 150
        })
      });

      const result = await response.json();
      return result.choices[0].message.content.trim();
    } catch (error) {
      return "Sorry, I encountered an error. Please try again.";
    }
  }

  async function getLLMSummary(userSummary, messages) {
    try {
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages: [
            { role: "system", content: "You are a medical assistant AI that summarizes patient check-ins with clear, friendly advice." },
            { role: "user", content: `Here is the patient data:\n${userSummary}\nSummarize the key points and suggest actions in a friendly tone.` }
          ],
          temperature: 0.5,
          max_tokens: 300
        })
      });

      const result = await response.json();
      const aiReply = result.choices[0].message.content;
      messages.innerHTML += `<p><strong>AI Summary:</strong> ${aiReply}</p>`;
    } catch (error) {
      messages.innerHTML += `<p><strong>AI Summary:</strong> Failed to generate summary.</p>`;
    }
  }

  document.getElementById('chatInput').addEventListener('keypress', function(e) {
    if (e.key === 'Enter') {
      sendMessage();
    }
  });
</script>
</body>
</html>
</file>

<file path="templates/index.html">
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>HealthHalo Dashboard</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 text-gray-900 font-sans">
  <div class="max-w-lg mx-auto mt-10 p-6 bg-white rounded-3xl shadow-xl">

    <!-- Header -->
    <div class="text-center mb-6">
      <div class="flex justify-center items-center gap-2">
        <img src="{{ url_for('static', filename='images/logo.png') }}" class="h-8" alt="Logo">
        <h1 class="text-2xl font-bold text-blue-900">HealthHalo</h1>
      </div>
      <p class="text-sm text-gray-600">Personalized AI-Driven Heart Disease Monitoring</p>
    </div>

    <!-- Nav Tabs -->
    <div class="flex justify-around mb-5 text-sm font-medium text-blue-700">
      <span class="border-b-2 border-blue-600 pb-1">Dashboard</span>
      <a href="{{ url_for('upload') }}" class="hover:underline">Upload Data</a>
      <a href="{{ url_for('chatbot') }}" class="hover:underline">Chat with AI</a>
    </div>

    <!-- Card: ML Risk Prediction -->
    <div class="bg-gray-100 rounded-xl p-4 mb-4">
      <div class="flex items-center gap-2 mb-1">
        <span class="text-blue-700">🧠</span>
        <h2 class="font-semibold text-gray-800">ML Risk Prediction</h2>
      </div>
      <p class="text-sm">Your readmission risk score is <strong>0.19</strong> – <span class="text-red-600 font-medium">High</span>.</p>
    </div>

    <!-- Card: LSTM Analysis -->
    <div class="bg-gray-100 rounded-xl p-4 mb-4">
      <div class="flex items-center gap-2 mb-1">
        <span class="text-blue-700">💙</span>
        <h2 class="font-semibold text-gray-800">LSTM Analysis</h2>
      </div>
      <p class="text-sm">Irregular heart rate patterns detected <strong>3×</strong> in the past week.</p>
    </div>

    <!-- Card: LLM Summary -->
    <div class="bg-gray-100 rounded-xl p-4 mb-4">
      <div class="flex items-center gap-2 mb-1">
        <span class="text-blue-700">💬</span>
        <h2 class="font-semibold text-gray-800">LLM Summary</h2>
      </div>
      <p class="text-sm">Patient reports increased fatigue and missed medication yesterday.</p>
    </div>

    <!-- Upload Section -->
    <div class="grid grid-cols-2 gap-4 mb-4">
      <div>
        <h3 class="text-sm font-semibold mb-1">⬆ Upload Data</h3>
        <button class="text-xs bg-white border rounded-md px-2 py-1 w-full mt-1 hover:bg-gray-100">Upload EHR (.csv)</button>
      </div>
      <div>
        <h3 class="text-sm font-semibold mb-1">📋 Reports</h3>
        <ul class="text-xs text-gray-700 space-y-1">
          <li><strong>Risk Score Trend:</strong> ⬆ Rising</li>
          <li><strong>HR Pattern Flags:</strong> 2 anomalies</li>
          <li><strong>Recent Symptoms:</strong> Fatigue, missed meds</li>
        </ul>
      </div>
    </div>

    <!-- Check-in Prompt (Now a Link to Chatbot) -->
    <a href="{{ url_for('chatbot') }}" class="block">
      <div class="bg-blue-50 rounded-xl p-3 text-center hover:bg-blue-100 transition-colors duration-200">
        <p class="text-blue-800 font-medium">😐 Hi! How are you feeling today?</p>
      </div>
    </a>

  </div>
</body>
</html>
</file>

<file path="README.md">
# HealthHalo-project
HealthHalo prevents hospital readmissions, as it will monitor and care for the patients after discharge.
</file>

<file path="app.py">
# app.py
import os
from flask import Flask, render_template, request, jsonify
import joblib
import pandas as pd
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# Print the folder path for debugging
print("App.py folder:", os.path.dirname(os.path.abspath(__file__)))

# Get base directory
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Load ML Model
model_path = os.path.join(BASE_DIR, 'HealthHalo-project', 'logistic_model.joblib')
model = joblib.load(model_path)

# Initialize Flask App
app = Flask(
    __name__,
    static_folder=os.path.join(BASE_DIR, 'static'),
    template_folder=os.path.join(BASE_DIR, 'templates')
)

# Routes
@app.route('/')
def dashboard():
    return render_template('index.html')  # Dashboard page

@app.route('/upload')
def upload():
    return render_template('upload.html')

@app.route('/chatbot')
def chatbot():
    return render_template('chatbot.html', openai_api_key=openai_api_key)  # Chatbot page with API key

@app.route('/predict', methods=['POST'])
def predict():
    """API Endpoint for ML Prediction"""
    data = request.get_json()
    try:
        features = data['features']
        input_df = pd.DataFrame([features])
        prob = model.predict_proba(input_df)[0][1]  # Risk Score
        pred_class = int(model.predict(input_df)[0])  # Class (e.g., 0 or 1)
        response = {
            'predicted_class': pred_class,
            'risk_score': prob
        }
        return jsonify(response)
    except Exception as e:
        return jsonify({'error': str(e)}), 400

if __name__ == '__main__':
    app.run(debug=True)
</file>

</files>
