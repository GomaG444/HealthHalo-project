

<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>HealthHalo Chat with AI</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 text-gray-900 font-sans">
  <div class="max-w-lg mx-auto mt-10 p-6 bg-white rounded-3xl shadow-xl">

    <!-- Header -->
    <div class="text-center mb-6">
      <div class="flex justify-center items-center gap-2">
        <img src="{{ url_for('static', filename='images/logo.png') }}" class="h-8" alt="Logo">
        <h1 class="text-2xl font-bold text-blue-900">HealthHalo Chat</h1>
      </div>
      <p class="text-sm text-gray-600">Your AI-powered health assistant</p>
    </div>

    <!-- Chatbox -->
    <div class="bg-gray-100 rounded-xl p-4 h-80 overflow-y-auto mb-4" id="chatMessages"></div>

    <!-- Input -->
    <div class="flex gap-2">
      <input type="text" id="chatInput" placeholder="Type your message..." class="flex-1 border border-gray-300 rounded-md px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-blue-400">
      <button onclick="sendMessage()" class="bg-blue-600 text-white rounded-md px-4 py-2 text-sm hover:bg-blue-700">Send</button>
    </div>

    <!-- Back Button -->
    <a href="{{ url_for('dashboard') }}" class="block mt-4 text-center text-blue-600 text-sm hover:underline">‚Üê Back to Dashboard</a>
  </div>

 <!-- Chat Script (Dynamic with OpenAI) -->
<script>
  let conversationStep = 0;
  let userData = {};

  // Use the API key passed from the Flask app
  const OPENAI_API_KEY = "{{ openai_api_key }}";

  async function sendMessage() {
    const input = document.getElementById('chatInput');
    const messages = document.getElementById('chatMessages');
    const userMessage = input.value.trim();
    if (!userMessage) return;

    messages.innerHTML += `<p><strong>You:</strong> ${userMessage}</p>`;
    messages.scrollTop = messages.scrollHeight;
    input.value = '';

    // Initial prompt to start conversation
    if (conversationStep === 0) {
      const prompt = "You are a friendly medical assistant AI. Start a conversation by asking about the user's health.";
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect symptoms
    else if (conversationStep === 1) {
      userData.symptoms = userMessage;
      const prompt = `You are a medical assistant AI. The user reported these symptoms: "${userData.symptoms}". Ask about their medication usage today.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect medications
    else if (conversationStep === 2) {
      userData.medications = userMessage;
      const prompt = `You are a medical assistant AI. The user reported these symptoms: "${userData.symptoms}" and medications: "${userData.medications}". Ask about their recent sleep, diet, or activity.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect lifestyle
    else if (conversationStep === 3) {
      userData.lifestyle = userMessage;
      const prompt = `You are a medical assistant AI. The user reported symptoms: "${userData.symptoms}", medications: "${userData.medications}", and lifestyle: "${userData.lifestyle}". Ask for their vitals in this format: age=55, sex=1, cholesterol=200, blood_pressure=120.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Collect vitals and get ML prediction
    else if (conversationStep === 4) {
      const features = {};
      userMessage.split(',').forEach(pair => {
        const [key, value] = pair.split('=').map(item => item.trim());
        if (key && value && !isNaN(value)) {
          features[key] = Number(value);
        }
      });

      if (Object.keys(features).length < 4) {
        messages.innerHTML += `<p><strong>AI:</strong> Please provide all four vitals correctly (age, sex, cholesterol, blood_pressure).</p>`;
        return;
      }

      try {
        const response = await fetch('/predict', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ features })
        });

        const data = await response.json();
        const riskScore = data.risk_score.toFixed(2);
        const predClass = data.predicted_class;

        const summary = `
Symptoms: ${userData.symptoms}
Medications: ${userData.medications}
Lifestyle: ${userData.lifestyle}
Vitals: ${JSON.stringify(features)}
Risk Score: ${riskScore}
Predicted Class: ${predClass}
        `;

        messages.innerHTML += `<p><strong>AI:</strong> Processing your data for a detailed summary...</p>`;
        await getLLMSummary(summary, messages);
      } catch (error) {
        messages.innerHTML += `<p><strong>AI:</strong> Failed to get risk score.</p>`;
      }

      const followUpPrompt = `You are a medical assistant AI. You have this patient data: "${summary}". Ask if they have other questions or want to schedule a check-in.`;
      const aiResponse = await getOpenAIResponse(followUpPrompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
      conversationStep++;
    }
    // Handle follow-up or end conversation
    else {
      const prompt = `You are a medical assistant AI. The user has completed their check-in. End the conversation politely and offer to talk again soon.`;
      const aiResponse = await getOpenAIResponse(prompt);
      messages.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
    }

    messages.scrollTop = messages.scrollHeight;
  }

  async function getOpenAIResponse(prompt) {
    try {
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages: [
            { role: "system", content: "You are a friendly medical assistant AI providing helpful and concise responses." },
            { role: "user", content: prompt }
          ],
          temperature: 0.7,
          max_tokens: 150
        })
      });

      const result = await response.json();
      return result.choices[0].message.content.trim();
    } catch (error) {
      return "Sorry, I encountered an error. Please try again.";
    }
  }

  async function getLLMSummary(userSummary, messages) {
    try {
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages: [
            { role: "system", content: "You are a medical assistant AI that summarizes patient check-ins with clear, friendly advice." },
            { role: "user", content: `Here is the patient data:\n${userSummary}\nSummarize the key points and suggest actions in a friendly tone.` }
          ],
          temperature: 0.5,
          max_tokens: 300
        })
      });

      const result = await response.json();
      const aiReply = result.choices[0].message.content;
      messages.innerHTML += `<p><strong>AI Summary:</strong> ${aiReply}</p>`;
    } catch (error) {
      messages.innerHTML += `<p><strong>AI Summary:</strong> Failed to generate summary.</p>`;
    }
  }

  document.getElementById('chatInput').addEventListener('keypress', function(e) {
    if (e.key === 'Enter') {
      sendMessage();
    }
  });
</script>
</body>
</html>

